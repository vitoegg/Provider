name: Update Rules

on:
  schedule:
    - cron: '0 */3 * * *'  # 每3小时执行一次
  workflow_dispatch:

env:
  # 规则配置 - 简单格式
  # 格式: RULE_名称_PATH=输出路径 和 RULE_名称_URLS=URL1 URL2 URL3
  
  # China规则
  RULE_CHINA_PATH: RuleSet/Direct/China.list
  RULE_CHINA_URLS: >-
    https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Surge/ChinaMax/ChinaMax_Domain.list
    https://raw.githubusercontent.com/Loyalsoldier/surge-rules/release/direct.txt
    https://raw.githubusercontent.com/vitoegg/Provider/master/RuleSet/Direct/LocalNet.list
  
  # Apple规则
  RULE_APPLE_PATH: RuleSet/Apple/Service.list
  RULE_APPLE_URLS: >-
    https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Surge/Apple/Apple_Domain.list
    https://raw.githubusercontent.com/Loyalsoldier/surge-rules/release/apple.txt
    https://raw.githubusercontent.com/Loyalsoldier/surge-rules/release/icloud.txt
  
  # Reject规则
  RULE_REJECT_PATH: RuleSet/Extra/Reject.list
  RULE_REJECT_URLS: >-
    https://ruleset.skk.moe/List/domainset/reject.conf
    https://ruleset.skk.moe/List/domainset/reject_extra.conf
    https://raw.githubusercontent.com/vitoegg/Provider/master/RuleSet/Extra/Privacy.list

jobs:
  update-rules:
    # 使用 Ubuntu 最新版本作为运行环境
    runs-on: ubuntu-latest
    outputs:
      has_changes: ${{ steps.check_changes.outputs.has_changes }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        id: checkout
        with:
          fetch-depth: 1  # 仅获取最近一次提交，加速检出过程

      - name: Setup Timezone
        run: sudo timedatectl set-timezone "Asia/Shanghai"
        id: timezone

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
        id: python

      - name: Create Processing Script
        id: create_script
        run: |
          echo "开始生成规则处理脚本..."
          echo "脚本功能: 下载规则、清理规则、合并规则、统计变化"
          echo "脚本结构: 3个主要函数 - 配置读取、规则处理、主程序"
          
          cat > process_rules.sh << 'EOF'
          #!/bin/bash
          set -eo pipefail

          # =====================================
          # 网络规则更新脚本
          # 功能: 下载、清理、去掉重复的规则
          # =====================================

          # 第一步: 从环境变量获取规则配置信息
          get_rules_config() {
            # 接收参数
            local -n rule_list="$1"   # 存放规则配置的数组
            local -n file_list="$2"   # 存放文件路径的数组
            
            echo "正在查找规则配置..."
            
            # 查找所有规则变量 (格式: RULE_规则名_PATH)
            for var in $(env | grep "^RULE_.*_PATH=" | cut -d= -f1); do
              # 从变量名中提取规则名称
              local rule_name=${var%_PATH}   # 去掉_PATH后缀
              rule_name=${rule_name#RULE_}   # 去掉RULE_前缀
              
              # 获取对应的URL变量名 (格式: RULE_规则名_URLS)
              local url_var="RULE_${rule_name}_URLS"
              
              # 检查URL变量是否存在
              if [[ -v $url_var ]]; then
                # 获取路径和URL值
                local path=${!var}             # 获取路径变量的值
                local urls=${!url_var}         # 获取URL变量的值
                
                # 显示找到的规则信息
                echo "找到规则: $rule_name"
                echo "- 保存路径: $path"
                echo "- 下载地址数量: $(echo "$urls" | wc -w)"
                
                # 保存规则信息到数组中
                rule_list["$rule_name"]="$path;$urls"  # 路径和URL用分号分隔
                file_list+=("$path")                   # 添加到文件列表
              fi
            done
            
            # 显示找到的规则总数
            echo "共找到 ${#rule_list[@]} 个规则"
          }

          # 第二步: 处理单个规则
          process_rule() {
            # 接收参数
            local rule_name="$1"      # 规则名称
            local output_path="$2"    # 输出文件路径
            local urls="$3"           # URL列表
            
            # 创建输出目录(如果不存在)
            local output_dir=$(dirname "$output_path")
            mkdir -p "$output_dir"
            
            echo "开始处理规则: $rule_name"
            echo "保存位置: $output_path"
            
            # 计时
            local start_time=$SECONDS
            
            # 2. 合并和清理规则
            echo "正在合并和清理规则..."
            
            # 创建临时文件和目录
            merged_file=$(mktemp)  # 合并后的文件
            cleaned_file=$(mktemp) # 清理后的文件
            tmp_dir=$(mktemp -d)   # 临时下载目录
            
            # 1. 下载规则文件
            echo "正在下载规则..."
            
            # 并行下载所有URL
            download_count=0
            download_pids=()
            
            for url in $urls; do
              # 为每个URL创建临时文件
              tmp_file="${tmp_dir}/download_${download_count}"
              
              # 后台下载并显示结果
              (curl -sL --fail --connect-timeout 10 --max-time 30 "$url" > "$tmp_file" && 
               echo "下载成功: $url" || 
               echo "下载失败: $url") &
              
              # 保存进程ID和计数
              download_pids+=($!)
              download_count=$((download_count + 1))
            done
            
            # 等待所有下载完成
            download_success=0
            for pid in "${download_pids[@]}"; do
              if wait $pid; then
                download_success=$((download_success + 1))
              fi
            done
            
            echo "下载完成: $download_success/$download_count 个文件成功下载"
            
            # 如果没有文件成功下载，报错并退出
            if [ $download_success -eq 0 ]; then
              echo "错误: 所有文件下载均失败，无法继续处理"
              echo "请检查网络连接或URL是否有效"
              return 1
            fi
            
            # 合并所有下载的文件
            shopt -s nullglob  # 设置shell选项，使通配符在没有匹配时返回空字符串
            downloads=("${tmp_dir}"/download_*)
            if [ ${#downloads[@]} -gt 0 ]; then
              cat "${downloads[@]}" > "$merged_file"
            else
              echo "警告: 没有下载到任何文件，创建空的合并文件"
              touch "$merged_file"
            fi
            shopt -u nullglob  # 恢复默认设置
            
            # 清理规则:
            # - 删除注释和空行
            # - 删除行首尾空格
            sed -e 's/[[:space:]]*[#;\/\/].*$//' \
                -e 's/^[[:space:]]*//;s/[[:space:]]*$//' \
                -e '/^$/d' \
                -e '/^[[:space:]]*[#;\/\/]/d' \
                -e '/^payload:/d' \
                -e '/^[[:space:]]*\/\*/d;/\*\//d' \
                "$merged_file" > "$cleaned_file"
            
            # 统计清理后的规则数量
            cleaned_count=$(wc -l < "$cleaned_file")
            echo "清理后的规则数量: $cleaned_count"
            
            # 3. 排序和去重
            if [[ -s "$cleaned_file" ]]; then
              echo "正在排序和去除重复项..."
              
              # 创建临时文件
              final_file=$(mktemp)      # 最终文件
              
              # 记录开始时间
              dedup_start=$SECONDS
              
              echo "开始高效处理规则..."
              
              # 为Python脚本添加执行权限
              chmod +x "$GITHUB_WORKSPACE/Script/Workflow/process_rules.py"
              
              # 使用外部Python脚本处理规则
              python3 "$GITHUB_WORKSPACE/Script/Workflow/process_rules.py" "$cleaned_file" > "$final_file" 2>/tmp/python_stats
              
              # 检查Python脚本是否成功执行
              if [ $? -ne 0 ]; then
                echo "Python处理失败，使用备用方案..."
                # 备用方案：使用基本排序去重
                sort -u "$cleaned_file" > "$final_file"
                echo "已使用基本排序和去重，跳过高级处理"
              else
                # 读取Python处理的统计信息
                if [ -f "/tmp/python_stats" ]; then
                  processing_time=$(grep "处理时间" /tmp/python_stats | awk '{print $2}')
                  total_rules=$(grep "总规则数" /tmp/python_stats | awk '{print $2}')
                  duplicate_rules=$(grep "重复规则" /tmp/python_stats | awk '{print $2}')
                  wildcard_covered=$(grep "泛域名被覆盖" /tmp/python_stats | awk '{print $2}')
                  exact_covered=$(grep "精确域名被覆盖" /tmp/python_stats | awk '{print $2}')
                  kept_rules=$(grep "保留规则" /tmp/python_stats | awk '{print $2}')
                  
                  # 显示总体去重耗时和统计信息
                  dedup_duration=$((SECONDS - dedup_start))
                  echo "规则处理完成，Python处理耗时: $processing_time 秒，总耗时: $dedup_duration 秒"
                  echo "去重统计:"
                  echo "- 原始规则数: $total_rules"
                  echo "- 去除重复规则: $duplicate_rules"
                  echo "- 去除被覆盖的泛域名: $wildcard_covered"
                  echo "- 去除被覆盖的精确域名: $exact_covered"
                  echo "- 保留规则数: $kept_rules"
                  echo "- 总计移除: $((total_rules - kept_rules)) 条规则"
                else
                  echo "警告: 无法获取处理统计信息"
                fi
              fi
              
              # 清理临时文件以释放内存
              rm -f /tmp/python_stats
              
              # 4. 添加元数据并保存
              echo "正在生成最终规则文件..."
              
              # 创建带有元数据的版本
              meta_file=$(mktemp)
              
              # 添加元数据
              {
                echo "# 规则来源:"
                for url in $urls; do
                  # 转换为GitHub仓库URL显示
                  repo_url=$(echo "$url" | sed -E 's|raw.githubusercontent.com/([^/]+/[^/]+).*|github.com/\1|')
                  echo "# - https://$repo_url"
                done
                echo ""
                # 添加规则内容
                cat "$final_file"
              } > "$meta_file"
              
              # 5. 检查是否有更改
              changed=0
              if [ -f "$output_path" ]; then
                # 比较旧文件和新文件(忽略更新时间)
                old_file=$(mktemp)
                grep -v "^# Update time:" "$output_path" > "$old_file"
                
                if ! cmp -s "$old_file" "$meta_file"; then
                  changed=1  # 文件有变化
                  # 计算增加和删除的规则数量
                  old_lines=$(grep -v "^#" "$old_file" | wc -l)
                  new_lines=$(grep -v "^#" "$meta_file" | wc -l)
                  added=$((new_lines > old_lines ? new_lines - old_lines : 0))
                  removed=$((old_lines > new_lines ? old_lines - new_lines : 0))
                  
                  echo "规则变化统计:"
                  echo "- 原有规则数量: $old_lines"
                  echo "- 新规则数量: $new_lines"
                  echo "- 变化: 新增 $added 条, 移除 $removed 条"
                  
                  # 记录变化统计到临时文件，供main函数读取
                  basename=$(basename "$output_path")
                  {
                    echo "规则变化统计:"
                    echo "- 原有规则数量: $old_lines"
                    echo "- 新规则数量: $new_lines" 
                    echo "- 变化: 新增 $added 条, 移除 $removed 条"
                  } > "/tmp/rule_changes_${basename}.log"
                fi
                rm -f "$old_file"
              else
                changed=1  # 文件不存在,需要创建
                new_lines=$(grep -v "^#" "$meta_file" | wc -l)
                echo "新建规则文件，包含 $new_lines 条规则"
                
                # 记录新建文件的统计到临时文件
                basename=$(basename "$output_path")
                {
                  echo "规则变化统计:"
                  echo "- 原有规则数量: 0"
                  echo "- 新规则数量: $new_lines" 
                  echo "- 变化: 新增 $new_lines 条, 移除 0 条"
                } > "/tmp/rule_changes_${basename}.log"
              fi
              
              # 如果有更改，写入新文件
              if [ $changed -eq 1 ]; then
                {
                  echo "# Update time: $(date '+%Y-%m-%d %H:%M:%S')"
                  cat "$meta_file"
                } > "$output_path"
                echo "规则已更新"
              else
                echo "规则无变化，无需更新"
              fi
              
              # 清理临时文件
              rm -f "$final_file" "$meta_file"
            else
              echo "警告: 没有找到有效内容，跳过处理"
            fi
            
            # 删除所有临时文件
            rm -f "$merged_file" "$cleaned_file"
            rm -rf "$tmp_dir"
            
            # 显示处理用时
            duration=$((SECONDS - start_time))
            echo "处理用时: $duration 秒"
          }

          # 主程序 - 控制整个处理流程
          main() {
            echo "===== 网络规则更新程序 ====="
            echo "开始时间: $(date '+%Y-%m-%d %H:%M:%S')"
            echo "============================"
            
            # 初始化数据结构
            declare -A rule_configs  # 存储规则配置
            declare -a rule_files    # 存储规则文件路径
            
            # 获取所有规则配置
            get_rules_config rule_configs rule_files
            
            # 如果没有找到规则，就退出
            if [ ${#rule_configs[@]} -eq 0 ]; then
              echo "没有找到规则配置，程序结束"
              return
            fi
            
            echo "============================"
            echo "开始更新规则"
            echo "============================"
            
            # 记录开始时间
            start_time=$SECONDS
            
            # 处理每个规则
            for rule_name in "${!rule_configs[@]}"; do
              # 分离路径和URL
              IFS=';' read -r output_path urls <<< "${rule_configs[$rule_name]}"
              
              echo "============================"
              # 处理规则
              process_rule "$rule_name" "$output_path" "$urls"
              echo "============================"
            done
            
            # 计算总耗时
            duration=$((SECONDS - start_time))
            echo "所有规则处理完成"
            echo "总用时: $((duration / 60))分$((duration % 60))秒"
            
            # 检测是否有变化
            has_changes=false
            change_summary=""
            total_added=0
            total_removed=0
            
            # 检查每个文件是否有实质变化 - 使用直接文件比较而非git diff
            for file in "${rule_files[@]}"; do
              if [ -f "$file" ]; then
                # 检查文件是否在处理过程中被修改（比较修改时间）
                file_mod_time=$(stat -c %Y "$file" 2>/dev/null || stat -f %m "$file" 2>/dev/null)
                current_time=$SECONDS
                
                # 如果文件是最近更新的（30秒内）
                if (( current_time - file_mod_time < 30 )); then
                  # 提取文件名并读取变化统计信息日志（从临时文件或变量）
                  basename=$(basename "$file")
                  # 从日志或输出中获取变化统计
                  added_lines=$(grep -A3 "规则变化统计:" /tmp/rule_changes_${basename}.log 2>/dev/null | grep "新增" | grep -o "[0-9]*" | head -1 || echo "0")
                  removed_lines=$(grep -A3 "规则变化统计:" /tmp/rule_changes_${basename}.log 2>/dev/null | grep "移除" | grep -o "[0-9]*" | head -1 || echo "0")
                  
                  # 如果有任何变化
                  if [ "$added_lines" != "0" ] || [ "$removed_lines" != "0" ]; then
                    has_changes=true
                    echo "文件有变化: $file"
                    echo "- 详细统计: 新增 $added_lines 条规则, 移除 $removed_lines 条规则"
                    
                    # 添加到变化摘要
                    change_summary="${change_summary}[$basename] +$added_lines/-$removed_lines "
                    
                    # 累计总变化量
                    total_added=$((total_added + added_lines))
                    total_removed=$((total_removed + removed_lines))
                  fi
                fi
              fi
            done
            
            # 添加总计到变化摘要
            if [ "$has_changes" = true ]; then
              change_summary="${change_summary}[总计] +$total_added/-$total_removed"
              echo "总变化: 新增 $total_added 条规则, 移除 $total_removed 条规则"
            fi
            
            # 设置输出变量
            if [ "$has_changes" = true ]; then
              echo "has_changes=true" >> "$GITHUB_OUTPUT"
              echo "change_summary=$change_summary" >> "$GITHUB_OUTPUT"
              echo "规则已更新，即将提交更改"
            else
              echo "has_changes=false" >> "$GITHUB_OUTPUT"
              echo "规则无变化，无需提交"
            fi
            
            echo "============================"
            echo "程序结束"
            echo "============================"
          }

          # 运行主程序
          main
          EOF
          
          chmod +x process_rules.sh
          echo "规则处理脚本已生成，权限设置为可执行"
          echo "脚本生成完成，将执行规则更新..."

      - name: Update RuleSets
        id: check_changes
        run: |
          echo "开始执行规则更新流程..."
          ./process_rules.sh

      - name: Commit and Push Changes
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          echo "检测到规则变更，准备提交..."
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # 使用变化摘要作为提交消息
          git commit -m "Auto update rules: ${{ steps.check_changes.outputs.change_summary }}"
          
          # 显示本次提交的统计信息
          echo "提交变更统计:"
          git show --stat --oneline HEAD
          
          echo "推送变更到仓库..."
          git push
        env:
          GITHUB_TOKEN: ${{ github.token }}

      - name: Delete Workflow Runs
        uses: Mattraks/delete-workflow-runs@v2
        with:
          token: ${{ github.token }}
          repository: ${{ github.repository }}
          retain_days: 0
          keep_minimum_runs: 2  # 保留最近2次运行记录，便于查看历史