name: Update Rules

on:
  schedule:
    - cron: '0 */3 * * *'  # 每3小时执行一次
  workflow_dispatch:

env:
  RULES_CONFIG: |
    rules:
      China:
        path: RuleSet/Direct/China.list
        urls:
          - https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Surge/ChinaMax/ChinaMax_Domain.list
          - https://raw.githubusercontent.com/Loyalsoldier/surge-rules/release/direct.txt
          - https://raw.githubusercontent.com/vitoegg/Provider/master/RuleSet/Direct/LocalNet.list
      
      Apple:
        path: RuleSet/Apple/Service.list
        urls:
          - https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Surge/Apple/Apple_Domain.list
          - https://raw.githubusercontent.com/Loyalsoldier/surge-rules/release/apple.txt
          - https://raw.githubusercontent.com/Loyalsoldier/surge-rules/release/icloud.txt
      
      Reject:
        path: RuleSet/Extra/Reject.list
        urls:
          - https://ruleset.skk.moe/List/domainset/reject.conf
          - https://ruleset.skk.moe/List/domainset/reject_extra.conf
          - https://raw.githubusercontent.com/vitoegg/Provider/master/RuleSet/Extra/Privacy.list

jobs:
  update-rules:
    runs-on: ubuntu-latest
    outputs:
      has_changes: ${{ steps.check_changes.outputs.has_changes }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Timezone
        run: sudo timedatectl set-timezone "Asia/Shanghai"

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Update RuleSets
        id: update_rules
        run: |
          # 从环境变量读取规则配置
          declare -A rule_configs
          while IFS= read -r line; do
            if [[ "$line" =~ ^[[:space:]]*([^:]+):[[:space:]]*$ ]]; then
              rule_name="${BASH_REMATCH[1]}"
              if [[ "$rule_name" != "rules" ]]; then
                # 读取path
                read -r path_line
                if [[ "$path_line" =~ ^[[:space:]]*path:[[:space:]]*([^[:space:]]+)[[:space:]]*$ ]]; then
                  path="${BASH_REMATCH[1]}"
                  # 读取urls
                  read -r urls_line
                  if [[ "$urls_line" =~ ^[[:space:]]*urls:[[:space:]]*$ ]]; then
                    urls=""
                    while IFS= read -r url_line; do
                      if [[ "$url_line" =~ ^[[:space:]]*-[[:space:]]*([^[:space:]]+)[[:space:]]*$ ]]; then
                        urls+="${BASH_REMATCH[1]} "
                      elif [[ "$url_line" =~ ^[[:space:]]*[^[:space:]] ]]; then
                        break
                      fi
                    done
                    rule_configs["$rule_name"]="$path;$urls"
                  fi
                fi
              fi
            fi
          done <<< "${{ env.RULES_CONFIG }}"
          
          for rule in "${!rule_configs[@]}"; do
            IFS=';' read -r output_path urls <<< "${rule_configs[$rule]}"
            echo "Updating $rule rules to $output_path..."
            
            # 创建临时文件数组
            temp_files=()
            for url in $urls; do
              temp_file=$(mktemp)
              echo "Downloading from $url..."
              curl -s "$url" > "$temp_file"
              temp_files+=("$temp_file")
            done
            
            # 合并并处理文件
            merged_file=$(mktemp)
            
            # 统一处理文件格式
            {
              # 根据文件类型添加不同的头部
              if [[ "$output_path" == *.yaml ]]; then
                echo "payload:"
              fi

              # 使用统一的 awk 脚本处理文件内容
              cat "${temp_files[@]}" | 
                awk -v file_type="${output_path##*.}" '
                  # 跳过注释行和空行
                  /^[[:space:]]*#/ { next }
                  /^[[:space:]]*$/ { next }
                  /^payload:/ { next }
                  {
                    # 移除行尾注释和空白字符
                    sub(/[[:space:]]*#.*$/, "")
                    gsub(/^[[:space:]]+|[[:space:]]+$/, "")
                    
                    # 处理特殊字符（针对不同格式）
                    if (file_type == "yaml") {
                      gsub(/\\/, "\\\\")  # 处理反斜杠
                      gsub(/"/, "\\\"")   # 处理双引号
                    }
                    
                    if ($0 != "") {
                      # 提取域名部分
                      domain = $0
                      prefix = ""
                      if (match(domain, /^([^:]+:[[:space:]]*)(.*)/, arr)) {
                        prefix = arr[1]
                        domain = arr[2]
                      }
                      
                      # 存储域名信息
                      if (!(domain in domains)) {
                        domains[domain] = $0
                        domain_prefixes[domain] = prefix
                      }
                    }
                  }
                  END {
                    # 对域名进行排序
                    n = asorti(domains, sorted_domains)
                    
                    # 第一遍：标记需要保留的域名
                    for (i = 1; i <= n; i++) {
                      domain = sorted_domains[i]
                      keep_domain[domain] = 1
                      
                      # 检查是否有更具体的域名
                      for (j = 1; j <= n; j++) {
                        other_domain = sorted_domains[j]
                        if (other_domain != domain && 
                            index(other_domain, domain) == 1 && 
                            substr(other_domain, length(domain) + 1, 1) == ".") {
                          keep_domain[domain] = 0
                          break
                        }
                      }
                    }
                    
                    # 第二遍：输出保留的域名
                    for (i = 1; i <= n; i++) {
                      domain = sorted_domains[i]
                      if (keep_domain[domain]) {
                        print domains[domain]
                      }
                    }
                  }
                ' | sort | uniq
            } > "$merged_file"
            
            # 确保输出目录存在
            mkdir -p "$(dirname "$output_path")"
            
            # 为了比较，创建一个不包含时间戳的临时文件
            temp_new_content=$(mktemp)
            {
              echo "# Merged from:"
              for url in $urls; do
                repo_url=$(echo "$url" | sed -E 's|raw.githubusercontent.com/([^/]+/[^/]+).*|github.com/\1|')
                echo "# - https://$repo_url"
              done
              echo ""
              cat "$merged_file"
            } > "$temp_new_content"
            
            # 如果原文件存在，创建一个不包含时间戳的版本用于比较
            temp_old_content=$(mktemp)
            if [ -f "$output_path" ]; then
              cat "$output_path" | grep -v "^# Update time:" > "$temp_old_content"
            else
              touch "$temp_old_content"
            fi
            
            # 比较文件内容（忽略时间戳）
            if ! cmp -s "$temp_old_content" "$temp_new_content"; then
              # 如果内容有实质性变化，则写入新文件（包含新的时间戳）
              {
                echo "# Update time: $(date '+%Y-%m-%d %H:%M:%S')"
                cat "$temp_new_content"
              } > "$output_path"
              echo "Changes detected in $rule rules."
            else
              echo "No changes detected in $rule rules."
            fi
            
            # 清理临时文件
            rm "${temp_files[@]}" "$merged_file" "$temp_new_content" "$temp_old_content"
          done

      - name: Check for Changes
        id: check_changes
        run: |
          # 从环境变量读取规则配置并提取所有文件路径
          declare -a files=()
          while IFS= read -r line; do
            if [[ "$line" =~ ^[[:space:]]*([^:]+):[[:space:]]*$ ]]; then
              rule_name="${BASH_REMATCH[1]}"
              if [[ "$rule_name" != "rules" ]]; then
                # 读取path
                read -r path_line
                if [[ "$path_line" =~ ^[[:space:]]*path:[[:space:]]*([^[:space:]]+)[[:space:]]*$ ]]; then
                  path="${BASH_REMATCH[1]}"
                  files+=("$path")
                fi
              fi
            fi
          done <<< "${{ env.RULES_CONFIG }}"
          
          changes_detected=false
          
          git add "${files[@]}"
          
          for file in "${files[@]}"; do
            # 获取git diff，排除时间戳行
            if git diff --cached --no-color "$file" | grep -v '^[+-]# Update time:' | grep -q '^[+-]'; then
              changes_detected=true
              break
            fi
          done
          
          if [ "$changes_detected" = true ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "Changes detected in rules files"
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "No changes detected in rules files"
            git restore --staged "${files[@]}"
          fi

      - name: Commit and Push Changes
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git commit -m "Auto update rules by action bot"
          git push
        env:
          GITHUB_TOKEN: ${{ github.token }}

      - name: Delete Workflow Runs
        uses: Mattraks/delete-workflow-runs@v2
        with:
          token: ${{ github.token }}
          repository: ${{ github.repository }}
          retain_days: 0
          keep_minimum_runs: 0
